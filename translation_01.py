import streamlit as st
import cohere
import os
from typing import List
import time

st.set_page_config(
    page_title="Traducteur Multilingue",
    page_icon="üåç",
    layout="wide",
    initial_sidebar_state="collapsed"
)

@st.cache_resource
def init_cohere_client():
    """Initialise le client Cohere en utilisant les secrets/variables d'environnement"""
    api_key = None
    
    # Essayer les secrets Streamlit d'abord (pour le d√©ploiement h√©berg√©)
    try:
        api_key = st.secrets["COHERE_API_KEY"]
    except (KeyError, FileNotFoundError):
        # Repli sur la variable d'environnement (pour le d√©veloppement local)
        api_key = os.getenv('COHERE_API_KEY')
    
    if not api_key:
        st.error("Cl√© API Cohere introuvable. Veuillez configurer COHERE_API_KEY dans les secrets Streamlit ou les variables d'environnement.")
        st.stop()
    
    return cohere.ClientV2(api_key)

# Configuration du mod√®le pour Aya 32B
MODEL_CONFIG = {
    "name": "Aya Expanse 32B", 
    "description": "Mod√®le multilingue 32B avec contexte √©tendu",
    "context_length": 131072,
    "max_output_tokens": 4096,
    "recommended_chunk_size": 2000
}

MODEL_NAME = "c4ai-aya-expanse-32b"

AYA_LANGUAGES = [
    "Arabe", "Chinois (Simplifi√©)", "Chinois (Traditionnel)", "Tch√®que", "N√©erlandais", 
    "Anglais", "Fran√ßais", "Allemand", "Grec", "H√©breu", "Hindi", "Indon√©sien", 
    "Italien", "Japonais", "Cor√©en", "Persan", "Polonais", "Portugais", 
    "Roumain", "Russe", "Espagnol", "Turc", "Ukrainien", "Vietnamien"
]

def split_text_into_chunks(text: str, chunk_size: int = 2000, overlap: int = 50) -> List[str]:
    """Divise le texte en segments avec chevauchement pour maintenir le contexte"""
    if len(text) <= chunk_size:
        return [text]
    
    chunks = []
    start = 0
    
    while start < len(text):
        end = start + chunk_size
        
        if end >= len(text):
            chunks.append(text[start:])
            break
        
        chunk = text[start:end]
        
        # Essayer de couper aux limites de phrases
        last_sentence = max(
            chunk.rfind('.'), 
            chunk.rfind('!'), 
            chunk.rfind('?')
        )
        
        if last_sentence > chunk_size * 0.7:
            end = start + last_sentence + 1
        else:
            # Repli sur les limites de mots
            last_space = chunk.rfind(' ')
            if last_space > chunk_size * 0.5:
                end = start + last_space
        
        chunks.append(text[start:end])
        start = end - overlap
    
    return chunks

def translate_chunk(client, text: str, target_lang: str, source_lang: str, temperature: float, context: str) -> str:
    """Traduit un seul segment en utilisant Cohere Aya"""
    system_prompt = f"{context.strip()} Traduisez le texte {source_lang} suivant en {target_lang}:"
    
    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": text}
    ]
    
    try:
        response = client.chat(
            model=MODEL_NAME,
            messages=messages,
            temperature=temperature,
            max_tokens=MODEL_CONFIG["max_output_tokens"]
        )
        return "".join(item.text for item in response.message.content if hasattr(item, 'text'))
    except Exception as e:
        st.error(f"√âchec de la traduction pour le segment: {str(e)}")
        return f"[√âchec de la traduction: {str(e)}]"

def main():
    st.title("üåç Traducteur Multilingue")
    st.markdown("Traduisez du texte avec une prise en compte contextuelle")
    
    # Initialiser le client Cohere
    client = init_cohere_client()
    
    # Configuration de la barre lat√©rale
    with st.sidebar:
        st.header("‚öôÔ∏è Param√®tres")
        
        # S√©lection des langues
        col1, col2 = st.columns(2)
        with col1:
            source_lang = st.selectbox(
                "De",
                AYA_LANGUAGES,
                index=AYA_LANGUAGES.index("Fran√ßais")
            )
        
        with col2:
            target_lang = st.selectbox(
                "Vers",
                AYA_LANGUAGES,
                index=AYA_LANGUAGES.index("Anglais")
            )
        
        st.divider()
        
        # Configuration des segments
        with st.expander("üìÑ Param√®tres Avanc√©s"):
            default_chunk_size = MODEL_CONFIG["recommended_chunk_size"]
            max_chunk_size = min(3000, MODEL_CONFIG["context_length"] // 4)
            
            chunk_size = st.slider(
                "Taille des segments (caract√®res)",
                min_value=500,
                max_value=max_chunk_size,
                value=default_chunk_size,
                step=100
            )
            
            chunk_overlap = st.slider(
                "Chevauchement des segments (caract√®res)",
                min_value=0,
                max_value=min(300, chunk_size // 4),
                value=50,
                step=10
            )
            
            temperature = st.slider(
                "Temp√©rature",
                min_value=0.0,
                max_value=1.0,
                value=0.1,
                step=0.1
            )
        
        # Informations sur le mod√®le
        with st.expander("‚ÑπÔ∏è √Ä propos"):
            st.write(f"**Mod√®le:** {MODEL_CONFIG['name']}")
            st.write(f"**Description:** {MODEL_CONFIG['description']}")
            st.write(f"**Longueur de contexte:** {MODEL_CONFIG['context_length']:,} tokens")
            st.write(f"**Langues:** 23 support√©es")
            
            st.markdown("---")
            st.markdown("**Propuls√© par Cohere AI**")
            st.markdown("Les mod√®les Aya Expanse de Cohere AI utilisent des techniques d'entra√Ænement avanc√©es pour l'excellence multilingue sur 23 langues.")
    
    # Interface principale
    col1, col2 = st.columns([1, 1])
    
    with col1:
        st.subheader(f"üéØ Contexte")
        context_text = st.text_area(
            "Contexte de traduction:",
            value="Vous √™tes un traducteur qui m'aide √† traduire des messages pour mon superviseur. Mon superviseur et moi parlons de mani√®re polie mais informelle. Je veux √™tre respectueux mais pas guind√©. R√©pondez uniquement avec la traduction et rien d'autre. Ne pas inclure de pr√©ambule, d'explication ou de commentaire. Donnez seulement le texte traduit. Voici le texte √† traduire:",
            height=120
        )
        
        st.subheader(f"üìù Texte ({source_lang})")
        input_text = st.text_area(
            "Texte √† traduire:",
            height=250,
            placeholder=f"Entrez votre texte en {source_lang} ici...",
            key="input_text_area"
        )
        
        # Option de t√©l√©chargement de fichier
        uploaded_file = st.file_uploader(
            "T√©l√©charger un fichier texte",
            type=['txt']
        )
        
        if uploaded_file is not None:
            input_text = uploaded_file.read().decode('utf-8')
            st.success(f"Fichier t√©l√©charg√© ! ({len(input_text):,} caract√®res)")
        
        # Comptage des caract√®res et segments estim√©s
        if input_text:
            char_count = len(input_text)
            estimated_chunks = max(1, (char_count + chunk_size - 1) // chunk_size)
            st.info(f"üìä {char_count:,} caract√®res ‚Ä¢ ~{estimated_chunks} segments")
    
    with col2:
        st.subheader(f"üåê Traduction ({target_lang})")
        
        # Create a form to enable Enter key functionality
        with st.form(key="translation_form", clear_on_submit=False):
            translate_clicked = st.form_submit_button("Traduire", type="primary", use_container_width=True)
        
        if translate_clicked:
            if not input_text.strip():
                st.warning("Veuillez entrer du texte √† traduire")
            elif not context_text.strip():
                st.warning("Veuillez fournir un contexte de traduction")
            elif source_lang == target_lang:
                st.warning("Les langues source et cible ne peuvent pas √™tre identiques")
            else:
                # Afficher le progr√®s de la traduction
                with st.spinner(f"Traduction avec {MODEL_CONFIG['name']}..."):
                    start_time = time.time()
                    
                    # Diviser le texte en segments
                    chunks = split_text_into_chunks(input_text, chunk_size, chunk_overlap)
                    
                    # Suivi du progr√®s
                    progress_bar = st.progress(0)
                    status_text = st.empty()
                    
                    translated_chunks = []
                    
                    for i, chunk in enumerate(chunks):
                        if chunk.strip():
                            status_text.text(f"Traduction du segment {i+1} sur {len(chunks)} avec {MODEL_CONFIG['name']}...")
                            
                            translated_chunk = translate_chunk(
                                client, chunk, target_lang, source_lang, temperature, context_text
                            )
                            translated_chunks.append(translated_chunk)
                            
                            # Mettre √† jour le progr√®s
                            progress_bar.progress((i + 1) / len(chunks))
                            time.sleep(0.1)
                    
                    # Combiner les segments traduits
                    full_translation = " ".join(translated_chunks)
                    translation_time = time.time() - start_time
                    
                    # Effacer les indicateurs de progr√®s
                    progress_bar.empty()
                    status_text.empty()
                    
                    # Stocker la traduction dans l'√©tat de session
                    st.session_state.translation = full_translation
                    st.session_state.chunks_processed = len(translated_chunks)
                    st.session_state.translation_time = translation_time
                    st.session_state.model_used = MODEL_CONFIG['name']
        
        # Afficher les r√©sultats de traduction
        if 'translation' in st.session_state:
            st.text_area(
                "Traduction:",
                value=st.session_state.translation,
                height=400,
                help=f"Trait√© {st.session_state.chunks_processed} segments en {st.session_state.translation_time:.1f}s avec {st.session_state.model_used}"
            )
            
            # Bouton de t√©l√©chargement
            st.download_button(
                label="T√©l√©charger",
                data=st.session_state.translation,
                file_name=f"traduction_{source_lang}_vers_{target_lang}.txt",
                mime="text/plain"
            )
            
            # Statistiques
            with st.expander("üìä Statistiques de Traduction"):
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.metric("Caract√®res d'entr√©e", f"{len(input_text):,}")
                with col2:
                    st.metric("Caract√®res de sortie", f"{len(st.session_state.translation):,}")
                with col3:
                    st.metric("Segments trait√©s", st.session_state.chunks_processed)
                with col4:
                    st.metric("Temps de traduction", f"{st.session_state.translation_time:.1f}s")

    # Pied de page avec informations sur le mod√®le
    with st.expander("üí° Informations sur le Mod√®le"):
        st.markdown(f"""
        **Mod√®le Actuel:** {MODEL_CONFIG['name']}
        
        **Langues Support√©es:** {', '.join(AYA_LANGUAGES)}
        
        **√Ä propos d'Aya Expanse:**
        - Mod√®les multilingues con√ßus pour une traduction de haute qualit√©
        - Optimis√©s pour 23 langues avec des techniques d'entra√Ænement avanc√©es
        - Traduction contextuelle avec support de segmentation pour les textes longs
        """)

if __name__ == "__main__":
    main()